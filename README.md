# Mini InSAR Pipeline v2 â€“ Professional Edition

A fully reproducible, GPUâ€‘accelerated InSAR processing pipeline built with Docker, SNAP, Python, and modern infrastructure practices. This project demonstrates how a single engineer can design, deploy, and operate a compact but productionâ€‘ready InSAR workflowâ€”covering data acquisition, preprocessing, interferogram generation, and displacement visualization.

The goal is to provide a **clean, minimal, operationally realistic reference pipeline** that can be integrated into GeoAI platforms, cloud/HPC environments, or national geospatial systems.

---

# ğŸš€ Key Capabilities

## **1. Endâ€‘toâ€‘End InSAR Workflow (Singleâ€‘Engineer Architecture)**

*   Automated search/download of Sentinelâ€‘1 SLC scenes (ASF)
*   SNAP graph processing (coregistration â†’ interferogram â†’ filtering)
*   GeoTIFF/VRT output for analysis and visualization
*   Simple Pythonâ€‘based displacement visualization + reporting
*   Fully reproducible Docker environment

## **2. GPUâ€‘Ready Infrastructure (Optional, Recommended)**

Supports GPU execution where possible, enabling:

*   Faster matrix operations
*   Faster unwrapping / filtering (future modules)
*   Local experimentation with OLLAMA + GPU inside Docker

## **3. GeoAIâ€‘First Design**

*   SAR automation with Python
*   Clean I/O layer (GeoTIFF, VRT, JSON)
*   Ready for ML extensions (e.g., coherence ML cleaners, PS selection)

## **4. Productionâ€‘Ready Engineering Practices**

*   Dockerfile + docker-compose orchestration
*   Isolated and reproducible runtime
*   Clear troubleshooting guides
*   WSL2 memory configuration for stable SNAP processing
*   [HPC Support Case Study (English)](./mini-insar-pipeline/HPC_SUPPORT_CASE_STUDY_EN.md)

---

# ğŸ¯ Project Status & Next Steps (ç¾åœ¨ã®é€²æ—ã¨æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—)

ç¾åœ¨ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®é€²æ—çŠ¶æ³ã¨ã€æ¬¡ã«é€²ã‚€ã¹ãã‚¹ãƒ†ãƒƒãƒ—ã‚’æ•´ç†ã—ã¾ã™ã€‚

## âœ” ç¾åœ¨ã®é€²æ—

*   **GPU ãƒ†ã‚¹ãƒˆæˆåŠŸ**: `gpu_test.py` ã‚’ä½¿ç”¨ã—ãŸGPUãƒ†ã‚¹ãƒˆã¯æˆåŠŸã—ã€Dockerã‚³ãƒ³ãƒ†ãƒŠå†…ã§ã®GPUã‚¢ã‚¯ã‚»ã‚¹ãŒç¢ºèªæ¸ˆã¿ã§ã™ã€‚
*   **GPT Graph æœ¬ç•ªå‡¦ç†æˆåŠŸ**: Master / Slave / Target Product ãŒæ­£ã—ãå‹•ä½œã—ã€å¹²æ¸‰ç”»åƒç”Ÿæˆï¼ˆInterferogramï¼‰ã¨ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ï¼ˆGoldstein filteringï¼‰ã¾ã§å®Œäº†ã—ã¾ã—ãŸã€‚
*   **Docker + SNAP + GPU + ASFãƒ‡ãƒ¼ã‚¿é€£æºæˆåŠŸ**: ã“ã‚ŒãŒæœ€å¤§ã®é›£é–¢ã§ã—ãŸãŒã€Dockerç’°å¢ƒã€ESA SNAPã€GPUãƒ‘ã‚¹ã‚¹ãƒ«ãƒ¼ã€ASFãƒ‡ãƒ¼ã‚¿é€£æºãŒã™ã¹ã¦æ­£å¸¸ã«æ©Ÿèƒ½ã—ã¦ã„ã¾ã™ã€‚

**ğŸ”¥ ã¤ã¾ã‚Šã€InSARãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®ç´„50%ãŒå®Œäº†ã—ãŸåœ°ç‚¹ã«ã„ã¾ã™ã€‚**
å¹²æ¸‰ç”»åƒï¼ˆInterferogramï¼‰ã¨ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ï¼ˆGoldstein filteringï¼‰ãŒçµ‚äº†ã—ãŸæ®µéšã§ã™ã€‚

## ğŸ“Œ æ¬¡ã«ã‚„ã‚‹ã¹ãä½œæ¥­ï¼ˆå„ªå…ˆé †ä½é †ï¼‰

ç¾åœ¨ã®ãƒ•ã‚©ãƒ«ãƒ€æ§‹æˆã¨é€²æ—ã«åŸºã¥ãã€æ¬¡ã«é€²ã‚€ã¹ãã‚¹ãƒ†ãƒƒãƒ—ã¯ä»¥ä¸‹ã®é€šã‚Šã§ã™ã€‚

### ğŸ¥‡ Step 1 â€” `run_gpt.py` ã‚’å®Œæˆã•ã›ã‚‹ï¼ˆä»Šã‚„ã‚‹ã¹ãæœ€é‡è¦ãƒã‚¤ãƒ³ãƒˆï¼‰

ç¾åœ¨ã€`scripts/run_gpt.py` ã‚’å®Œæˆã•ã›ã€InSARãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’CLIã‹ã‚‰å®Œå…¨ã«è‡ªå‹•åŒ–ã™ã‚‹ã“ã¨ã‚’ç›®æŒ‡ã—ã¾ã™ã€‚Master/Slaveã®ãƒ‘ã‚¹ã€Graph Pathã€å‡ºåŠ›ãƒ‘ã‚¹ã‚’Pythonã‚¹ã‚¯ãƒªãƒ—ãƒˆã§æ¸¡ã›ã‚‹ã‚ˆã†ã«ã—ã¾ã™ã€‚

**ä¾‹:**
```bash
python scripts/run_gpt.py \
  --master /opt/data/...SAFE \
  --slave /opt/data/...SAFE \
  --graph graphs/insar_graph.xml \
  --output /opt/data/out
```
ã“ã‚Œã«ã‚ˆã‚Šã€ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ãŒã€Œå®Œå…¨è‡ªå‹•å‡¦ç†ã€ã«ãªã‚Šã¾ã™ã€‚

### ğŸ¥ˆ Step 2 â€” SNAPHUã«ã‚ˆã‚‹ä½ç›¸ã‚¢ãƒ³ãƒ©ãƒƒãƒ—ï¼ˆUnwrappingï¼‰

ç¾åœ¨ã®ã‚°ãƒ©ãƒ•ã§ã¯ã€å‡¦ç†ã¯Interferogramã¨Filteringã§æ­¢ã¾ã£ã¦ã„ã¾ã™ã€‚å¤‰ä½ã‚’ç®—å‡ºã™ã‚‹ãŸã‚ã«ã¯ã€ä½ç›¸ã‚¢ãƒ³ãƒ©ãƒƒãƒ—ãŒå¿…è¦ã§ã™ã€‚

**ã‚ªãƒ—ã‚·ãƒ§ãƒ³:**
*   Dockerå†…ã§SNAPHUã‚’ãƒ“ãƒ«ãƒ‰ã—ã¦æ¥ç¶šã™ã‚‹ï¼ˆDockerfileã«æ•°è¡Œè¿½åŠ ã§å¯èƒ½ï¼‰ã€‚
*   SNAPã®SNAPHU-Exportæ©Ÿèƒ½ã‚’åˆ©ç”¨ã—ã€SNAPHUã‚’å®Ÿè¡Œå¾Œã€çµæœã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆã™ã‚‹ï¼ˆã‚¹ã‚¯ãƒªãƒ—ãƒˆåŒ–å¯èƒ½ï¼‰ã€‚

### ğŸ¥‰ Step 3 â€” LOSå¤‰ä½ã«å¤‰æ›ï¼ˆPhase â†’ Displacementï¼‰

SNAPHUã§ã‚¢ãƒ³ãƒ©ãƒƒãƒ—ã•ã‚ŒãŸä½ç›¸ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ã€ä»¥ä¸‹ã®è¨ˆç®—å¼ã§å¤‰ä½é‡ï¼ˆãƒŸãƒªãƒ¡ãƒ¼ãƒˆãƒ«å˜ä½ï¼‰ã‚’ç®—å‡ºã—ã¾ã™ã€‚
`unwrapped_phase Ã— (Î» / 4Ï€)`
ã“ã‚Œã¯Pythonï¼ˆNumPyãªã©ï¼‰ã§ç°¡å˜ã«è‡ªå‹•åŒ–ã§ãã¾ã™ã€‚

### ğŸ… Step 4 â€” GeoTIFF ç”Ÿæˆï¼ˆ`convert_vrt_to_tif.py`ã®æ´»ç”¨ï¼‰

`scripts/convert_vrt_to_tif.py` ã¯ã€DIM â†’ VRT â†’ GeoTIFFã¸ã®å¾Œå‡¦ç†ç”¨ã‚¹ã‚¯ãƒªãƒ—ãƒˆã§ã™ã€‚InSARã®æœ€çµ‚æˆæœç‰©ã¨ã—ã¦GeoTIFFå½¢å¼ãŒæœ›ã¾ã—ã„ãŸã‚ã€ã“ã®ã‚¹ãƒ†ãƒƒãƒ—ã¾ã§ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’æ¥ç¶šã—ã¾ã™ã€‚

### ğŸ–ï¸ Step 5 â€” `generate_report.py` ã§è‡ªå‹•ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆï¼ˆä»»æ„ï¼‰

PDFã¾ãŸã¯Markdownå½¢å¼ã§ã®è‡ªå‹•ãƒ¬ãƒãƒ¼ãƒˆç”ŸæˆãŒå¯èƒ½ãªæ§‹æˆã§ã™ã€‚
**ç†æƒ³ã®ãƒ¬ãƒãƒ¼ãƒˆå†…å®¹:**
*   å…¥åŠ›ãƒšã‚¢æƒ…å ±
*   ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ (bperp)
*   ã‚³ãƒ’ãƒ¼ãƒ¬ãƒ³ã‚¹ãƒãƒƒãƒ—
*   å¤‰ä½ãƒãƒƒãƒ—
*   å¯è¦–åŒ–å›³

---

# ğŸ“¦ System Requirements

### **Windows 10/11 + WSL2 + Docker Desktop**

*   WSL2 backend **required**
*   NVIDIA GPU + latest drivers
*   Docker Desktop with **GPU support enabled**

### **Python 3.10+ (host only for utility scripts)**

Used only for optional helper tools.

---

# âš™ï¸ 1. Prepare Earthdata Login (Required)

The pipeline uses **ASF Search API**, which requires NASA Earthdata credentials.

Set environment variables before running Docker:

### **PowerShell (Windows)**

```powershell
$env:EARTHDATA_USERNAME="your_earthdata_username"
$env:EARTHDATA_PASSWORD="your_earthdata_password"
```

### **Bash (Linux/WSL)**

```bash
export EARTHDATA_USERNAME=your_earthdata_username
export EARTHDATA_PASSWORD=your_earthdata_password
```
*Replace `your_earthdata_username` and `your_earthdata_password` with your actual credentials.*

---

# âš™ï¸ 2. Configure WSL2 Resources (Critical for SNAP)

SNAP requires **high RAM**. Without this, the process will freeze or be killed.

Create or edit:

```
%USERPROFILE%\.wslconfig
```

Add:

```ini
[wsl2]
memory=16GB
processors=6
swap=16GB
localhostForwarding=true
```

Apply changes:

```powershell
wsl --shutdown
```

Restart Docker Desktop.

Verify memory:

```bash
free -h
```

---

# âš™ï¸ 3. Install OLLAMA + GPU Support (Optional, Recommended)

This pipeline is designed so you can:

*   run OLLAMA on Windows host,
*   expose GPU into Docker,
*   accelerate SAR processing + AIâ€‘based SAR assistants.

**OLLAMA Install (Windows):**
[https://ollama.com/download](https://ollama.com/download)

Verify GPU access:

```powershell
ollama run llama3 "Test GPU"
```

---

# âš™ï¸ 4. Verify Docker GPU Access

### Test with CUDA Base Image

```powershell
docker run --rm --gpus all nvidia/cuda:12.2.0-base-ubuntu22.04 nvidia-smi
```

### Test PyTorch GPU (for future ML modules)

```powershell
docker run --rm --gpus all -it pytorch/pytorch:2.3.0-cuda12.1-cudnn8-runtime \  
python -c "import torch; print(torch.cuda.is_available(), torch.cuda.get_device_name(0))"
```

Should output:

```
True NVIDIA GeForce RTX 4060 Laptop GPU
```

If this works, GPU passthrough is ready.

---

## 6. Example Pipeline Execution

### Step 1 â€” Download Sentinelâ€‘1 SLC (Optional)

If you already have the Sentinel-1 `.SAFE` data in `./data/SAFE/`, you can skip this step.

```bash
python /opt/scripts/download_data.py \
  --start 2021-05-11 \
  --end   2021-05-11 \
  --aoi   /opt/data/aoi.geojson
```

### Step 2 â€” Run SNAP InSAR Graph

Execute the InSAR processing graph using ESA SNAP's Graph Processing Tool (GPT). This step performs co-registration, interferogram formation, topographic phase removal, and filtering.

**To measure execution time, you can prefix the command with `time`:**

```bash
time gpt /opt/graphs/insar_graph.xml \
  -Pmaster=/opt/data/SAFE/S1A_IW_SLC__1SDV_20210511T173941_20210511T174008_037843_047769_9526.SAFE \
  -Pslave=/opt/data/SAFE/S1A_IW_SLC__1SDV_20210530T173150_20210530T173217_038120_047FBA_A0C2.SAFE \
  -Ptarget_product=/opt/data/out/insar_filtered.dim
```

**Important:** Replace the placeholder `.SAFE` paths with the actual paths to your master and slave Sentinel-1 data within the container (e.g., `/opt/data/SAFE/YOUR_MASTER_IMAGE.SAFE`).

```bash
gpt /opt/graphs/insar_graph.xml \
  -Pmaster=/opt/data/SAFE/S1A_IW_SLC__1SDV_20210511T173941_20210511T174008_037843_047769_9526.SAFE \
  -Pslave=/opt/data/SAFE/S1A_IW_SLC__1SDV_20210530T173150_20210530T173217_038120_047FBA_A0C2.SAFE \
  -Ptarget_product=/opt/data/out/insar_filtered.dim
```

This command will take some time to complete, depending on your system resources and the size of the data.

### Step 3 â€” Convert VRT â†’ GeoTIFF

```bash
python /opt/scripts/convert_vrt_to_tif.py /opt/data/out
```

### Step 4 â€” Generate Report

```bash
python /opt/scripts/generate_report.py /opt/data/out
```

---



---

## 5.2 What is SNAP Graph Execution? (InSAR Processing for Beginners)

The `insar_graph.xml` file used here defines a sequence of automated processing steps for Sentinel-1 radar data, executed by ESA SNAP's Graph Processing Tool (GPT). This process transforms raw satellite data into an interferogram, which can reveal millimeter-scale ground movements.

Here's a simplified breakdown:

1.  **Co-registration:**
    *   **What:** Accurately aligns two satellite images taken at different times over the same area. Imagine precisely stacking two photos of the same landscape taken days apart.
    *   **Why:** Essential for comparing the tiny phase differences between them to detect movement.
2.  **Interferogram Formation:**
    *   **What:** Creates an "interferogram" by measuring the phase difference (a property of radar waves) between the two co-registered images. This phase difference appears as a pattern of fringes (like contour lines).
    *   **Why:** These fringes contain information about ground deformation and topography.
3.  **Topographic Phase Removal:**
    *   **What:** Removes the part of the phase difference caused by the shape of the terrain (mountains, valleys). We only want the phase related to ground movement.
    *   **Why:** Isolates the phase changes directly caused by ground deformation, making them easier to observe.
4.  **Phase Filtering (e.g., Goldstein Filter):**
    *   **What:** Reduces noise in the interferogram, making the fringe patterns clearer and more interpretable.
    *   **Why:** Improves the quality of the deformation signal and helps in unwrapping the phase later.
5.  **Output (e.g., GeoTIFF):**
    *   **What:** Saves the processed interferogram into a standard geospatial format.
    *   **Why:** Allows for further analysis and visualization in GIS software.

**Important Note on GPU Usage:**
While this Docker environment is fully GPU-enabled, SNAP's core InSAR processing (including the `gpt` command with `insar_graph.xml`) is primarily **CPU-bound**. This means the GPU is not actively used during these specific InSAR steps. The GPU setup is crucial for **AI/Deep Learning workloads** (e.g., PyTorch, TensorFlow) and **Large Language Models (LLMs)** via tools like Ollama, which can leverage the GPU within this environment. This project demonstrates a versatile environment capable of both CPU-bound geospatial processing and GPU-accelerated AI tasks.

```
mini-insar-pipeline/
â”‚   docker-compose.yml
â”‚   Dockerfile
â”‚   README.md
â”‚
â”œâ”€â”€ scripts/
â”‚     download_data.py
â”‚     run_snap_graph.py
â”‚     convert_vrt_to_tif.py
â”‚     generate_report.py
â”‚     gpu_test.py
â”‚     gpu_test.py
â”‚
â”œâ”€â”€ graphs/
â”‚     insar_graph.xml
â”‚
â””â”€â”€ data/
      SAFE/
      out/
```

---

# Validation & Expected Outputs

After running the pipeline, you should find the following in the `mini-insar-pipeline/data/out/` directory:

*   `insar_filtered.tif`: The filtered interferogram (phase-filtered).
*   `insar_filtered.tif.png`: A visualization of the interferogram.
*   `insar_report.txt`: A short textual report with output paths.

### Sanity Checks
*   The interferogram should show coherent fringes over non-vegetated areas (coastal/urban).
*   If the interferogram is noisy (low coherence), try picking acquisition dates that are closer together.
*   If outputs are empty or you encounter an error, check the SNAP GPT logs printed to the console. Common issues include incorrect `.SAFE` paths or a missing manifest file.

---

# ğŸ”§ Troubleshooting

For common issues and their resolutions, please refer to the [TROUBLESHOOTING.md](mini-insar-pipeline/TROUBLESHOOTING.md) file.

---

# ğŸ“ Learning Points & Demonstrated Skills

This project, especially the troubleshooting process, offers valuable insights for those interested in High-Performance Computing (HPC) or geospatial roles, directly aligning with skills sought in roles like a Cloud Infrastructure Engineer. It demonstrates practical experience in:

*   **Modern Scientific Computing Approach (Reproducibility & GeoAI Integration)**:
    *   **Demonstrated Skill**: This project exemplifies a modern approach to scientific computing by containerizing complex geospatial processing workflows (InSAR) within a Linux-based Docker environment. This strategy effectively resolves common path and dependency issues (e.g., with GDAL/PROJ) often encountered on Windows, ensuring cross-platform reproducibility and stability. Furthermore, by integrating GPU passthrough, the environment is not only robust for CPU-bound tasks like ESA SNAP's InSAR processing but also fully equipped for GPU-accelerated AI/ML workloads (e.g., PyTorch, Ollama). This dual capability showcases a best practice in GeoAI, where traditional geospatial analysis is seamlessly combined with cutting-edge AI, optimizing resource utilization and fostering innovation.
    *   **Relevance to Roles**: Essential for roles in scientific computing, GeoAI development, and MLOps, demonstrating the ability to build reproducible, high-performance computing environments that bridge traditional scientific workflows with modern AI/ML capabilities.

*   **Cloud Infrastructure & DevOps (AWS, Docker, IaC, GitHub Actions, Serverless, Kubernetes)**:
    *   **Demonstrated Skill**: Experience in defining and managing infrastructure (Docker containers, dependencies, resource allocation) through code (`Dockerfile`, `docker-compose.yml`). This ensures consistent and reproducible environments across different systems, a core principle of IaC. The iterative process of building, testing, and refining the Docker image reflects DevOps practices. Familiarity with containerization (Docker) and orchestration concepts (Kubernetes, AWS EKS) is also highlighted.
    *   **Relevance to Roles**: This skill is highly relevant to roles requiring expertise in cloud infrastructure, DevOps practices, and managing deployments in environments like AWS. It demonstrates experience with Infrastructure as Code (IaC) using tools like Docker and an understanding of cloud-based service architectures, including serverless and container orchestration (e.g., Kubernetes, AWS EKS).

*   **Programming & Development (Python Scripting, Automation, Data Processing)**:
    *   **Demonstrated Skill**: Automating complex scientific workflows (InSAR processing) using Python scripting and containerization. This involves software development practices that support data processing, scripting, and automation.
    *   **Relevance to Roles**: This skill is crucial for roles involving software development, particularly in data processing, scripting, and automation, often utilizing languages like Python.

*   **Geospatial Technology (Data Formats, Processing Workflows, GDAL, STAC)**:
    *   **Demonstrated Skill**: Practical knowledge of InSAR workflows, ESA SNAP, and processing pipelines within a containerized environment. This involves handling specialized geospatial data and tools, including the use of GDAL for data conversion and understanding of metadata standards like STAC.
    *   **Relevance to Roles**: This skill is essential for roles focused on geospatial data, including processing workflows, spatial analysis, and the delivery of essential geospatial products, often involving tools like GDAL and standards like STAC.

*   **Resource Management & Optimization (Disk I/O, CPU/RAM, Docker Cleanup)**:
    *   **Demonstrated Skill**: Understanding how to manage computational resources, especially disk space and RAM, is fundamental. Encountering and resolving `[Errno 5]` (I/O errors) due to full disk space, or processes being `Killed` due to insufficient RAM, highlights practical experience. This includes using tools like `wsl --shutdown`, `Optimize-VHD`, and crucially, `docker system prune -a` for reclaiming significant disk space (e.g., over 18GB after multiple build attempts).
    *   **Relevance to Roles**: This skill is vital for roles involving cloud architecture, system administration, and performance optimization, where efficient resource management and problem-solving for performance issues are critical.

*   **Problem-Solving & Troubleshooting Mindset**:
    *   **Demonstrated Skill**: The iterative process of identifying errors (e.g., `404 Not Found` for SNAP installer, `gdal-config not found`, `Python configuration failed`), hypothesizing causes, testing solutions, and documenting findings is central to any technical role. This project involved debugging version mismatches, environmental inconsistencies, and dependency issues.
    *   **Relevance to Roles**: This skill is fundamental for any technical role, emphasizing a practical, outcome-driven approach to identifying, diagnosing, and resolving complex technical challenges.

*   **Communication and Documentation**:
    *   **Demonstrated Skill**: The proactive attitude to summarize acquired knowledge into clear documentation (`README.md`, `TROUBLESHOOTING.md`) for the benefit of other technical professionals and the community. This includes translating technical concepts for both general and technical audiences.
    *   **Relevance to Roles**: This skill is crucial for effectively conveying technical information to diverse audiences, contributing to knowledge sharing, user training, and overall project clarity.

---

# Troubleshooting Experience from a Contributor

When I first ran this pipeline, I encountered various errors and found it very challenging. Therefore, I would like to share what I learned: this debugging journey is a very normal, everyday process.

Tackling these problems is exactly what professional researchers and engineers do daily. The errors I faced were the kind of issues they resolve every day.

*   Simple input mistakes in file paths that are easy to overlook.
*   Syntax issues in the graph XML file that required updates to match the software version.
*   Insufficient disk space that needed cleanup.

With each error I resolved, I felt I was steadily moving forward. This trial-and-error process is not a sign of failure. Rather, it is an essential and valuable experience in the field of actual scientific and technical computing. So, if you encounter errors, it is a sign that you are on the right track.

---

# ğŸ“„ Licensing

## Code Licensing

This pipeline's code is provided as-is. If you intend to publish or distribute this code, it is highly recommended to choose and include an appropriate open-source license (e.g., MIT, Apache 2.0) in your repository. This clarifies how others can use, modify, and distribute your code.

## Data Licensing

The Sentinel-1 data downloaded via this pipeline is sourced from the Alaska Satellite Facility (ASF). While ASF data is generally publicly funded and available, specific usage policies, especially concerning commercial applications, can vary by dataset.

**It is crucial for users to consult the End User License Agreements (EULAs) associated with each specific data collection to determine the exact commercial use policy and any other restrictions.**

---



---

# Troubleshooting Experience from a Contributor

When I first ran this pipeline, I encountered various errors and found it very challenging. Therefore, I would like to share what I learned: this debugging journey is a very normal, everyday process.

Tackling these problems is exactly what professional researchers and engineers do daily. The errors I faced were the kind of issues they resolve every day.

*   Simple input mistakes in file paths that are easy to overlook.
*   Syntax issues in the graph XML file that required updates to match the software version.
*   Insufficient disk space that needed cleanup.

With each error I resolved, I felt I was steadily moving forward. This trial-and-error process is not a sign of failure. Rather, it is an essential and valuable experience in the field of actual scientific and technical computing. So, if you encounter errors, it is a sign that you are on the right track.

---

# ğŸ“„ Licensing

## Code Licensing

This pipeline's code is provided as-is. If you intend to publish or distribute this code, it is highly recommended to choose and include an appropriate open-source license (e.g., MIT, Apache 2.0) in your repository. This clarifies how others can use, modify, and distribute your code.

## Data Licensing

The Sentinel-1 data downloaded via this pipeline is sourced from the Alaska Satellite Facility (ASF). While ASF data is generally publicly funded and available, specific usage policies, especially concerning commercial applications, can vary by dataset.

**It is crucial for users to consult the End User License Agreements (EULAs) associated with each specific data collection to determine the exact commercial use policy and any other restrictions.**

---

# ğŸ“„ Future Extensions

*   GPUâ€‘accelerated filtering/unwrapping
*   PyTorchâ€‘based coherence cleaning
*   Realâ€‘time deformation dashboards
*   Integration with OLLAMA LLM agents
*   National-scale cloud deployment examples

---

# ğŸ“¨ Contact / Notes

This pipeline was built to demonstrate how an engineer can deliver **endâ€‘toâ€‘end SAR processing systems** aloneâ€”suitable for evaluation by national geospatial institutions.

Feel free to adapt, extend, or integrate this into your own GeoAI stack.